% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_mae.R
\name{sits_mae}
\alias{sits_mae}
\title{Pre-train a Masked Autoencoder on SITS time-series data}
\usage{
sits_mae(
  encoder_model = "lighttae",
  decoder_model = "mlp",
  masking_method = "contiguous",
  mask_ratio = 0.6,
  epochs = 150L,
  batch_size = 128L,
  validation_split = 0.2,
  optimizer_fn = torch::optim_adamw,
  loss_fn = torch::nnf_mse_loss,
  device = if (torch::cuda_is_available()) torch::torch_device("cuda") else
    torch::torch_device("cpu"),
  lr = 0.001,
  verbose = FALSE,
  output_dir = NULL
)
}
\arguments{
\item{encoder_model}{Character. Which encoder backbone to use. Supported values:
`"lighttae"` (temporal attention encoder) or
`"tempcnn"` (1D convolutional).}

\item{decoder_model}{Character. Which decoder head to use. Currently only `"mlp"`.}

\item{masking_method}{Character. How to select masked positions. One of
`"random"` or `"contiguous"`.}

\item{mask_ratio}{Numeric in (0,1). Fraction of time-steps to mask.}

\item{epochs}{Integer. Number of training epochs.}

\item{batch_size}{Integer. Batch size for both training and validation.}

\item{validation_split}{Numeric in (0,1). Fraction of samples held out for validation.}

\item{optimizer_fn}{Function. A `torch` optimizer constructor (e.g. `torch::optim_adamw`).}

\item{loss_fn}{Function. A `torch` loss function (e.g. `torch::nnf_mse_loss`).}

\item{device}{`torch::device` or string. Where to perform training
(e.g. `"cpu"` or `torch::cuda_device()`).}

\item{lr}{Numeric. Initial learning rate for the optimizer.}

\item{verbose}{Logical. If `TRUE`, print per-epoch training/validation losses.}

\item{output_dir}{Character. Optional. Path to save model log.}
}
\value{
A function with signature `function(samples)` which, when called on a SITS
samples object, trains a masked autoencoder and returns the pretrained encoder
(as a `torch` module).
}
\description{
`sits_mae()` returns a training-factory function for a Masked Autoencoder (MAE)
that you can pass to [sits_pre_train()].  The resulting closure takes a SITS
`samples` object, runs a self-supervised reconstruction loop over masked time-steps,
and returns the pretrained encoder.
}
\references{
He, K., Chen, X., Xie, S., Li, Y., Doll√°r, P., & Girshick, R. (2022).
*Masked Autoencoders Are Scalable Vision Learners*. Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).
}
\author{
Alexandre Assuncao \email{alexcarssuncao@gmail.com}
}
